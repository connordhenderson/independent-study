{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "from collections import Counter\n",
    "from functools import reduce \n",
    "import operator\n",
    "import itertools\n",
    "from scipy.stats import median_absolute_deviation\n",
    "\n",
    "# util\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# visualization & graphing;\n",
    "import graphviz\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "from graphviz import render\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "fdir = \"../data/queries_explains_10g/queries1tb/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAN_COSTS = ['Cumulative Total Cost',\n",
    "'Cumulative CPU Cost',\n",
    "'Cumulative I/O Cost',\n",
    "'Cumulative Re-Total Cost',\n",
    "'Cumulative Re-CPU Cost',\n",
    "'Cumulative Re-I/O Cost',\n",
    "'Cumulative First Row Cost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_regex = re.compile(r\"(Access Plan:)+\")\n",
    "plan_details_regex = re.compile(r\"(Plan Details:)+\")\n",
    "\n",
    "# get the relationships for the parent/child nodes\n",
    "relationship_regex = re.compile(r\"(\\/|\\+)(-+\\+)+-+(\\\\|\\+)|\\|\")    #5\n",
    "\n",
    "# get the node type or table schema\n",
    "type_regex = re.compile(r\"(\\w+((:(\\+|-| )*)|-)*)+\\w+\")            #1\n",
    "\n",
    "# get the node label or table name\n",
    "label_regex = re.compile(r\"\\d+|\\w+\")                              #2\n",
    "\n",
    "# separates by WS\n",
    "not_ws_regex = re.compile(r\"\\S+\")                                 #3\n",
    "\n",
    "# looks for various float representations\n",
    "float_regex = re.compile(r\"(\\d+(.\\d+){0,1}(e(\\+|-)\\d+){0,1})\")    #\n",
    "\n",
    "# used to find the labels for plan details\n",
    "pd_label_regex = re.compile(r\"^\\s?\\d+\\)\")\n",
    "\n",
    "# strips '#-#-' prefix from the label of form '#-#-@' by ignoring the #-#- capture group\n",
    "strip_label_regex = re.compile(r\"(?:(\\w+-){2})(\\S+)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_graph(g, view=False, root=None):\n",
    "    if root is None:\n",
    "        nodes = g.nodes\n",
    "        edges = g.edges\n",
    "    else:\n",
    "        nodes, edges = g.get_graph()[root].get_subgraph()\n",
    "    \n",
    "    _g = graphviz.Digraph('g', node_attr={'shape': 'record', 'height': '.1'})\n",
    "    for n in nodes:\n",
    "        if str(n[0]) == \"0\":\n",
    "            continue\n",
    "        _g.node(str(n[0]), str(n[1]))\n",
    "\n",
    "    for e in edges:\n",
    "        if str(e[1]) == \"0\":\n",
    "            continue\n",
    "        _g.edge(str(e[0]), str(e[1]))\n",
    "\n",
    "    if view:\n",
    "        try:\n",
    "            _g.view()\n",
    "        except:\n",
    "            pass\n",
    "    else:\n",
    "        return _g\n",
    "    \n",
    "    \n",
    "def visualize_joins(g):\n",
    "    joins = g.get_graph()['1-0-1'].get_join_nodes()\n",
    "    joins = [visualize_graph(g, root=j) for j in joins]\n",
    "    return joins\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict(f, dct):\n",
    "    np.save('../data/output_qep/' + f + '.npy', dct) \n",
    "\n",
    "def load_dict(f):\n",
    "    # try to load a saved dict\n",
    "    result = {}\n",
    "    try:\n",
    "        result = np.load('../data/output_qep/' + f + '.npy',allow_pickle='TRUE').item()\n",
    "    except FileNotFoundError:\n",
    "        print('no ' + f + ' file found at \\'../data/output_qep/' + f + '.npy\\'')\n",
    "    return result\n",
    "\n",
    "def canonical(s):\n",
    "    return \"temp\" if s.isdigit() else s\n",
    "\n",
    "# returns the center (float) point between two ints in a tuple\n",
    "def center(tup):\n",
    "    return (tup[0] + tup[1])/2\n",
    "\n",
    "# determines the size of the span of a tuple of int's\n",
    "def span(s):\n",
    "    return s[1] - s[0]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "@param  rels   list(tup):  a list of tuples that represent the spans of the given edges for a line\n",
    "@param  val    int:        the value of the center which we'd like to find the containing edge for\n",
    "@return result int:        the index of the relationship that contains the edge\n",
    "\"\"\"\n",
    "def get_parent_relationship(rels, val):\n",
    "    # added dummy -2-1 so we can return -1 for no match\n",
    "    result = np.argmax([val > rel[0] and val <= rel[1] for rel in [(-2,-1)] + rels], -1)\n",
    "    return result - 1\n",
    "\n",
    "def strip_label(label):\n",
    "    return strip_label_regex.search(label).group(2)\n",
    "\n",
    "\n",
    "def test_ownership(r, c, allow_doubles = False):\n",
    "    result = [get_parent_relationship(r, _c) for _c in c]\n",
    "    \n",
    "    if allow_doubles:\n",
    "        return result\n",
    "    \n",
    "    for i in range(1, len(result)):\n",
    "        # if we encounter edges sequentially and they aren't -1 then find the closest center\n",
    "        if result[i - 1] == result[i] and result[i] > 0:\n",
    "            if abs(c[i] - center(r[result[i]])) >= abs(c[i - 1] - center(r[result[i]])):\n",
    "                result[i] = -1\n",
    "            else:\n",
    "                result[i - 1] = -1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "#      -> deal with IDs consistently (str, int, label?)\n",
    "\n",
    "\"\"\"\n",
    "The nodes of the graph represent the low level plan operators (LOLEPOPS) in the query execution plan;\n",
    "ultimately we'd like to expand on Node2Vec to include additional node features\n",
    "@param idx       (int):     node index\n",
    "@param parent    (node):    parent node\n",
    "@param label     (int):     node class label from node_types dict\n",
    "@param attr      (list):    additional nodes/features (NYI)\n",
    "\"\"\"\n",
    "class node:\n",
    "    def __init__(self, idx, attr=None):        \n",
    "        self.idx   = idx\n",
    "        self.attr  = attr\n",
    "        self.children = []\n",
    "        \n",
    "    def insert(self, node):\n",
    "        self.children.append(node)\n",
    "    \n",
    "    def get_children(self):\n",
    "        return self.children\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"[id#{self.idx}: children: {[c.idx for c in self.get_children()]}]\"\n",
    "    \n",
    "    def get_all_terminal(self):\n",
    "        if self.children == []:\n",
    "            return [self.idx]\n",
    "        result =  reduce(operator.concat, [child.get_all_terminal() for child in self.get_children()])\n",
    "        return result\n",
    "    \n",
    "    def get_join_nodes(self, current_node = None):\n",
    "        if current_node is None:\n",
    "            current_node = self\n",
    "            \n",
    "        joins = []\n",
    "        children = current_node.get_children()\n",
    "        if len(children) > 1:\n",
    "            joins.append(current_node.idx)\n",
    "        elif children == []:\n",
    "            return []\n",
    "\n",
    "        for child in children:\n",
    "            joins += child.get_join_nodes(child)\n",
    "        return joins\n",
    "    \n",
    "    def get_subgraph(self, parent = None):\n",
    "        edges = []\n",
    "        nodes = []\n",
    "        \n",
    "        if parent is not None:\n",
    "            edges.append((strip_label(parent.idx), strip_label(self.idx)))\n",
    "            nodes.append((strip_label(self.idx),strip_label(self.idx)))\n",
    "            \n",
    "        if len(self.children) > 0:\n",
    "            for child in self.children:\n",
    "                \n",
    "                child_nodes, child_edges = child.get_subgraph(self)\n",
    "                \n",
    "                for edge in child_edges:\n",
    "                    edges.append(edge)\n",
    "                    \n",
    "                for node in child_nodes:\n",
    "                    nodes.append(node)\n",
    "                    \n",
    "        return nodes, edges "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a directed graph-structure that stores a list of nodes and edges (pairs of node indices) of \n",
    "a graph from a SQL Explain Plan. The structure can be parsed from the 'Action Plan' and the features can\n",
    "be extracted from the 'Plan Details'\n",
    "@param exfmt (str):  SQL Explain Plan from DB2\n",
    "\"\"\"\n",
    "class digraph:\n",
    "    def __init__(self, exfmt):\n",
    "        self.file = fdir + exfmt\n",
    "        self.head = None\n",
    "        self.node_dict = {}\n",
    "        \n",
    "        self.nodes, self.edges, self.labels = self.get_access_plan()\n",
    "        self.plan_details = self.get_plan_details()\n",
    "        \n",
    "    \"\"\"\n",
    "    Get Access Plan\n",
    "    \"\"\"\n",
    "    def get_access_plan(self):\n",
    "        node_types = load_dict('node_types')\n",
    "        node_labels = load_dict('node_labels')\n",
    "        \n",
    "        ap_start = None\n",
    "        ap_end   = None\n",
    "        \n",
    "        prv_nodes = None\n",
    "        edges = None\n",
    "        prv_edges = None\n",
    "        \n",
    "        _nodes = []\n",
    "        _edges = []\n",
    "        _labels = {}\n",
    "        \n",
    "        # tracking line-counts for debugging & printing portions of the explain plan\n",
    "        lx       = 0\n",
    "        lines    = ''\n",
    "        depth    = 0\n",
    "        \n",
    "        with open(self.file) as f:\n",
    "            lines = f.readlines()\n",
    "            \n",
    "        # getting the access plan:    \n",
    "        # iteration over sql explain plan format file\n",
    "        for line in lines:\n",
    "            # incr. line index\n",
    "            lx += 1\n",
    "\n",
    "            # track access plan boundaries for debugging\n",
    "            if ap_start is None:\n",
    "                if access_regex.search(line):\n",
    "                    ap_start = lx + 5 #offset\n",
    "            elif ap_end is None and line[0] == '-' and lx - ap_start > 1:\n",
    "                ap_end = lx\n",
    "\n",
    "        lines = lines[ap_start:ap_end]\n",
    "        \n",
    "        lx       = ap_start\n",
    "        # parsing the AP 6 lines at a time (height of the layers in the explain plan):\n",
    "        while len(lines) >= 6:        \n",
    "            lx += 6\n",
    "            depth += 1\n",
    "            \n",
    "            # create the nodes\n",
    "            # get table-names; figure out where they're centered and identify relationship. first, remove ws after ':'\n",
    "            node_cardinality = [l for l in not_ws_regex.finditer(lines[0])]\n",
    "            \n",
    "            # convert node types to IDs so they're consistent between query plans. if it's not in a dict, put it in\n",
    "            node_type = [l for l in type_regex.finditer(lines[1])]\n",
    "            for i in range(len(node_type)):\n",
    "                try:\n",
    "                    node_types[str(node_type[i].group(0))]\n",
    "                except KeyError:\n",
    "                    node_types[str(node_type[i].group(0))] = len(node_types) + 1\n",
    "                    continue  \n",
    "\n",
    "            # convert node labels to IDs so they're consistent between query plans. if it's not in a dict, put it in\n",
    "            node_label = [l for l in label_regex.finditer(lines[2])]\n",
    "            for i in range(len(node_label)):\n",
    "                try:\n",
    "                    node_labels[str(node_label[i].group(0))]\n",
    "                except KeyError:\n",
    "                    node_labels[str(node_label[i].group(0))] = len(node_labels) + 1\n",
    "                    continue          \n",
    "            \n",
    "            node_attr = [l for l in not_ws_regex.finditer(lines[3])]\n",
    "            \n",
    "            # put them into an easy to work with vector form\n",
    "            nodes = np.vstack((node_cardinality, node_type, node_label, node_attr)).T           \n",
    "            \n",
    "            # get the indices of the node features with the longest length\n",
    "            centers = [np.argmax([len(n_.group(0)) for n_ in n]) for n in nodes]\n",
    "            # get the matches those of indices; find the center of the spans of those matches\n",
    "            centers = [int(center(nodes[i][centers[i]].span())) for i in range(len(nodes))]\n",
    "            \n",
    "            # get edges; expand boundaries by 2 to account for 2 char buffer on each side\n",
    "            edges = [(r.span()[0] - 2, r.span()[1] + 2) for r in relationship_regex.finditer(lines[5])] \n",
    "\n",
    "            edge_owner = test_ownership(edges, centers)\n",
    "            \n",
    "            # add the nodes to the node list\n",
    "            for i in range(len(nodes)):\n",
    "                _nodes.append((str(depth)+'-'+str(i)+'-'+nodes[i][2].group(0), nodes[i][2].group(0)))\n",
    "                _labels[nodes[i][2].group(0)] = nodes[i][1].group(0)\n",
    "    \n",
    "            if prv_edges == None:\n",
    "                # continue to the next layer\n",
    "                self.head = nodes[0]\n",
    "                pass\n",
    "\n",
    "            else:\n",
    "                # BUG: some overlapping tables are getting edges when they shouldn't be (check empty (4) spot?)\n",
    "                # get all possible edges that could be the parents; grab the closest match and use it's index\n",
    "                candidate_parents = test_ownership(prv_edges, centers, True)\n",
    "                #print(candidate_parents)\n",
    "                for i in range(len(candidate_parents)):\n",
    "                    for j in range(len(prv_edge_owner)):\n",
    "                        if candidate_parents[i] == prv_edge_owner[j]:\n",
    "                            #e = (prv_nodes[j][2].group(0) , nodes[i][2],group(0))\n",
    "                            \n",
    "                            # \"depth-node#-label\"\n",
    "                            e1 = str(depth - 1)+'-'+str(j)+'-'+prv_nodes[j][2].group(0)\n",
    "                            e2 = str(depth)+'-'+str(i)+'-'+ nodes[i][2].group(0)\n",
    "                            \n",
    "                            _edges.append((e1,e2))\n",
    "                            #print(e)\n",
    "\n",
    "            # continue to the next layer\n",
    "            prv_nodes      = nodes\n",
    "            prv_edges      = edges\n",
    "            prv_centers    = centers\n",
    "            prv_edge_owner = edge_owner\n",
    "            lines = lines[6:]\n",
    "\n",
    "        save_dict('node_types', node_types)\n",
    "        save_dict('node_labels', node_labels)\n",
    "        return _nodes, _edges, _labels\n",
    "\n",
    "    \"\"\"\n",
    "    Plan Details\n",
    "    \"\"\"\n",
    "    def get_plan_details(self):\n",
    "        pd_start = None\n",
    "        pd_end   = None\n",
    "        lx       = 0\n",
    "        lines    = ''\n",
    "        \n",
    "        plan_details = {}\n",
    "        \n",
    "        with open(self.file) as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        for line in lines:\n",
    "            lx += 1\n",
    "        \n",
    "            if pd_start is None:\n",
    "                if plan_details_regex.search(line):\n",
    "                    pd_start = lx + 1 #offset\n",
    "            elif pd_end is None and line[0] == '-' and lx - pd_start > 1:\n",
    "                pd_end = lx\n",
    "        lines = lines[pd_start:pd_end]\n",
    "\n",
    "        while len(lines) > 9:\n",
    "            # get the node label '\\S?#)' and extract label\n",
    "            label = pd_label_regex.search(lines[0])\n",
    "            if label:\n",
    "                label = float_regex.search(label.group(0)).group(0)\n",
    "                \n",
    "                # get the costs and associate them to the node\n",
    "                node_costs = [float_regex.search(lines[i + 1]).group(0) for i in range(len(PLAN_COSTS))]\n",
    "                plan_details[int(label)] = node_costs\n",
    "                \n",
    "            lines = lines[1:]\n",
    "        return plan_details\n",
    "    \n",
    "    # Get the joins that are present in the table using the local labels\n",
    "    def get_joins(self, node_types = None, terminal_dict = None):\n",
    "        if node_types is None:\n",
    "            node_types = load_dict('node_types')\n",
    "        if terminal_dict is None:\n",
    "            terminal_dict = load_dict('terminal_dict')\n",
    "            \n",
    "        nodes = self.get_graph()\n",
    "\n",
    "        # Get the nodes that represent a join in the graph (by counting # of children)\n",
    "        joins = Counter([edge[0] for edge in self.edges])\n",
    "        joins = [j for j in joins if joins[j] >= 2]\n",
    "\n",
    "        # get all the terminal nodes from those joins\n",
    "        joins = [(j, nodes[j].get_all_terminal()) for j in nodes if j in joins]\n",
    "        \n",
    "        # strip the labels\n",
    "        joins = np.array([(strip_label(j[0]), [strip_label(_j) for _j in j[1]]) for j in joins], dtype=object)\n",
    "     \n",
    "        return joins\n",
    "    \n",
    "    # return a list of all of the terminal nodes (tables? the ordinal values returned are temp. tables)\n",
    "    def get_terminal_nodes(self):\n",
    "        res = np.setdiff1d([e[1] for e in g.edges], [e[0] for e in g.edges]).tolist()\n",
    "        res = np.array([strip_label(e) for e in res])\n",
    "        return res\n",
    "    \n",
    "    def get_graph(self):\n",
    "        nodes = {}\n",
    "        for edge in self.edges:\n",
    "            if edge[0] not in nodes:\n",
    "                nodes[edge[0]] = node(edge[0])\n",
    "            if edge[1] not in nodes:\n",
    "                nodes[edge[1]] = node(edge[1])\n",
    "            nodes[edge[0]].insert(nodes[edge[1]])\n",
    "        return nodes\n",
    "    \n",
    "def qep2vec(graph, degree = 0):\n",
    "    joins = graph.get_joins()\n",
    "\n",
    "    if degree > 0:\n",
    "        joins = np.array([join for join in joins if len(join[1]) <= degree], dtype=object)\n",
    "\n",
    "    # table names => integers\n",
    "    joins[:,0] = np.vectorize(int)(joins[:,0])\n",
    "\n",
    "    # create the costs column\n",
    "    joins = np.hstack([joins, np.zeros((len(joins), 1))])\n",
    "\n",
    "    # get the costs\n",
    "    for i in range(len(joins[:,0])):\n",
    "        joins[:,2][i] = np.vectorize(float)(graph.plan_details[joins[:,0][i]])\n",
    "\n",
    "    # table names => integers\n",
    "    joins[:,0] = np.vectorize(str)(joins[:,0])\n",
    "\n",
    "    # get the corresponding named types from the node labels\n",
    "    joins[:,0] = np.vectorize(graph.labels.get)(joins[:,0])\n",
    "\n",
    "    # load the canonical node types; match the labels to their canonical symbol\n",
    "    node_types = load_dict('node_types')\n",
    "    joins[:,0] = np.vectorize(node_types.get)(joins[:,0])\n",
    "\n",
    "    # load the canonical table names...\n",
    "    terminal_dict = load_dict('terminal_dict')\n",
    "    for i in range(len(joins[:,1])):\n",
    "        a = np.array(joins[:,1][i][0])\n",
    "        for j in range(len(joins[:,1][i])):\n",
    "            joins[:,1][i][j] = terminal_dict[canonical(joins[:,1][i][j])]\n",
    "\n",
    "    # using the lengths from the global dicts, and np.put, we create the table/type indicator vectors\n",
    "    # and combine them with the cost\n",
    "    type_ind = np.zeros((len(joins), len(node_types)))\n",
    "    table_ind = np.zeros((len(joins), len(terminal_dict)))\n",
    "\n",
    "    # turn the indices into indicator vectors\n",
    "    for i in range(len(joins)):\n",
    "        np.put(table_ind[i], joins[:,1][i],1)\n",
    "        np.put(type_ind[i], joins[:,0][i], 1)\n",
    "\n",
    "    # concat the axis along Nx7 ( 7 costs being measured )\n",
    "    costs = np.concatenate(joins[:,2], axis=0).reshape(len(joins),7)\n",
    "    return [len(node_types), len(terminal_dict), np.hstack((type_ind, table_ind, costs))]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
